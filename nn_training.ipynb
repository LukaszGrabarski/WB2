{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, XLMRobertaModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/embeddings_train_x.csv')\n",
    "y = pd.read_csv('data/train.csv')['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate plot of variance explained vs number of components\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "def plot_variance_explained_vs_components(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    # add a horizontal line at 95% and 90%\n",
    "    plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "    plt.axhline(y=0.90, color='g', linestyle='--')\n",
    "    # calculate the number of components that explain 95% and 90% of the variance\n",
    "    n_components_95 = np.where(np.cumsum(pca.explained_variance_ratio_) > 0.95)[0][0]\n",
    "    n_components_90 = np.where(np.cumsum(pca.explained_variance_ratio_) > 0.90)[0][0]\n",
    "    plt.axvline(x=n_components_95, color='r', linestyle='--')\n",
    "    plt.axvline(x=n_components_90, color='g', linestyle='--')\n",
    "    # mark at x axis the number of components that explain 95% and 90% of the variance\n",
    "    plt.text(n_components_95, 0.7, f'n_components = {n_components_95}')\n",
    "    plt.text(n_components_90, 0.5, f'n_components = {n_components_90}')\n",
    "    plt.show()\n",
    "\n",
    "plot_variance_explained_vs_components(X_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=35)\n",
    "X_train_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33663366336633666\n",
      "[[155 137 144]\n",
      " [145 126 118]\n",
      " [148 112 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.36      0.35       436\n",
      "           1       0.34      0.32      0.33       389\n",
      "           2       0.33      0.33      0.33       387\n",
      "\n",
      "    accuracy                           0.34      1212\n",
      "   macro avg       0.34      0.34      0.34      1212\n",
      "weighted avg       0.34      0.34      0.34      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_pca, y_train)\n",
    "y_pred = rf.predict(pca.transform(X_val))\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3721122112211221\n",
      "[[180 110 146]\n",
      " [137 134 118]\n",
      " [151  99 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.41      0.40       436\n",
      "           1       0.39      0.34      0.37       389\n",
      "           2       0.34      0.35      0.35       387\n",
      "\n",
      "    accuracy                           0.37      1212\n",
      "   macro avg       0.37      0.37      0.37      1212\n",
      "weighted avg       0.37      0.37      0.37      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, max_depth=10, min_samples_leaf=1, min_samples_split=5)\n",
    "rf.fit(X_train_pca, y_train)\n",
    "y_pred = rf.predict(pca.transform(X_val))\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3314 - loss: 1.2217 - val_accuracy: 0.3336 - val_loss: 1.0974\n",
      "Epoch 2/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3533 - loss: 1.0969 - val_accuracy: 0.3419 - val_loss: 1.0955\n",
      "Epoch 3/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3505 - loss: 1.0945 - val_accuracy: 0.3538 - val_loss: 1.0944\n",
      "Epoch 4/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3558 - loss: 1.0917 - val_accuracy: 0.3593 - val_loss: 1.0935\n",
      "Epoch 5/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3503 - loss: 1.0936 - val_accuracy: 0.3611 - val_loss: 1.0924\n",
      "Epoch 6/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3573 - loss: 1.0904 - val_accuracy: 0.3731 - val_loss: 1.0906\n",
      "Epoch 7/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3670 - loss: 1.0887 - val_accuracy: 0.3859 - val_loss: 1.0858\n",
      "Epoch 8/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.0884 - val_accuracy: 0.4115 - val_loss: 1.0846\n",
      "Epoch 9/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3765 - loss: 1.0850 - val_accuracy: 0.4070 - val_loss: 1.0765\n",
      "Epoch 10/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3954 - loss: 1.0772 - val_accuracy: 0.4326 - val_loss: 1.0708\n",
      "Epoch 11/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4035 - loss: 1.0724 - val_accuracy: 0.4152 - val_loss: 1.0728\n",
      "Epoch 12/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3995 - loss: 1.0672 - val_accuracy: 0.4445 - val_loss: 1.0655\n",
      "Epoch 13/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4148 - loss: 1.0650 - val_accuracy: 0.4262 - val_loss: 1.0634\n",
      "Epoch 14/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4205 - loss: 1.0564 - val_accuracy: 0.4436 - val_loss: 1.0644\n",
      "Epoch 15/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.0492 - val_accuracy: 0.4427 - val_loss: 1.0609\n",
      "Epoch 16/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.0483 - val_accuracy: 0.4482 - val_loss: 1.0526\n",
      "Epoch 17/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4233 - loss: 1.0458 - val_accuracy: 0.4363 - val_loss: 1.0503\n",
      "Epoch 18/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4126 - loss: 1.0478 - val_accuracy: 0.4528 - val_loss: 1.0515\n",
      "Epoch 19/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4300 - loss: 1.0398 - val_accuracy: 0.4317 - val_loss: 1.0528\n",
      "Epoch 20/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4255 - loss: 1.0454 - val_accuracy: 0.4693 - val_loss: 1.0305\n",
      "Epoch 21/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4377 - loss: 1.0434 - val_accuracy: 0.4372 - val_loss: 1.0497\n",
      "Epoch 22/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4481 - loss: 1.0225 - val_accuracy: 0.4427 - val_loss: 1.0373\n",
      "Epoch 23/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4487 - loss: 1.0300 - val_accuracy: 0.4500 - val_loss: 1.0377\n",
      "Epoch 24/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4488 - loss: 1.0305 - val_accuracy: 0.4363 - val_loss: 1.0444\n",
      "Epoch 25/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4528 - loss: 1.0275 - val_accuracy: 0.4500 - val_loss: 1.0311\n",
      "Epoch 26/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4566 - loss: 1.0193 - val_accuracy: 0.4418 - val_loss: 1.0449\n",
      "Epoch 27/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4415 - loss: 1.0369 - val_accuracy: 0.4354 - val_loss: 1.0438\n",
      "Epoch 28/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4610 - loss: 1.0238 - val_accuracy: 0.4409 - val_loss: 1.0400\n",
      "Epoch 29/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4449 - loss: 1.0158 - val_accuracy: 0.4253 - val_loss: 1.0500\n",
      "Epoch 30/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4462 - loss: 1.0290 - val_accuracy: 0.4455 - val_loss: 1.0333\n",
      "Epoch 31/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4622 - loss: 1.0111 - val_accuracy: 0.4546 - val_loss: 1.0442\n",
      "Epoch 32/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4586 - loss: 1.0105 - val_accuracy: 0.4702 - val_loss: 1.0266\n",
      "Epoch 33/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4631 - loss: 1.0110 - val_accuracy: 0.4491 - val_loss: 1.0329\n",
      "Epoch 34/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4630 - loss: 1.0176 - val_accuracy: 0.4482 - val_loss: 1.0286\n",
      "Epoch 35/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4556 - loss: 1.0183 - val_accuracy: 0.4812 - val_loss: 1.0265\n",
      "Epoch 36/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4755 - loss: 1.0055 - val_accuracy: 0.4730 - val_loss: 1.0250\n",
      "Epoch 37/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4658 - loss: 1.0089 - val_accuracy: 0.4409 - val_loss: 1.0393\n",
      "Epoch 38/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4697 - loss: 1.0039 - val_accuracy: 0.4583 - val_loss: 1.0275\n",
      "Epoch 39/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 1.0054 - val_accuracy: 0.4665 - val_loss: 1.0216\n",
      "Epoch 40/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4810 - loss: 0.9913 - val_accuracy: 0.4510 - val_loss: 1.0417\n",
      "Epoch 41/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4704 - loss: 1.0044 - val_accuracy: 0.4629 - val_loss: 1.0255\n",
      "Epoch 42/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4716 - loss: 1.0008 - val_accuracy: 0.4748 - val_loss: 1.0267\n",
      "Epoch 43/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 1.0028 - val_accuracy: 0.4427 - val_loss: 1.0397\n",
      "Epoch 44/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4739 - loss: 1.0043 - val_accuracy: 0.4675 - val_loss: 1.0196\n",
      "Epoch 45/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4723 - loss: 1.0007 - val_accuracy: 0.4528 - val_loss: 1.0215\n",
      "Epoch 46/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4857 - loss: 0.9905 - val_accuracy: 0.4299 - val_loss: 1.0473\n",
      "Epoch 47/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4646 - loss: 1.0053 - val_accuracy: 0.4620 - val_loss: 1.0237\n",
      "Epoch 48/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4714 - loss: 1.0089 - val_accuracy: 0.4427 - val_loss: 1.0269\n",
      "Epoch 49/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4768 - loss: 1.0050 - val_accuracy: 0.4702 - val_loss: 1.0209\n",
      "Epoch 50/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4790 - loss: 0.9939 - val_accuracy: 0.4601 - val_loss: 1.0211\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_val_encoded = to_categorical(y_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer and first hidden layer\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add second hidden layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(units=y_train_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4730 - loss: 1.0265\n",
      "Test accuracy: 0.4587458670139313\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Accuracy: 0.45874587458745875\n",
      "Confusion Matrix:\n",
      "[[315 103  18]\n",
      " [242 128  19]\n",
      " [201  73 113]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.72      0.53       436\n",
      "           1       0.42      0.33      0.37       389\n",
      "           2       0.75      0.29      0.42       387\n",
      "\n",
      "    accuracy                           0.46      1212\n",
      "   macro avg       0.53      0.45      0.44      1212\n",
      "weighted avg       0.53      0.46      0.44      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val_encoded)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_val_encoded, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(X_train, y_train, X_val, y_val, optimizer='adam', init='glorot_uniform', epochs=50, batch_size=32):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer=init, input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer=init))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    return model, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create a representative sample of the data (e.g., 20% of the dataset)\n",
    "X_sample, _, y_sample, _ = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=16, epochs=50, optimizer=SGD, init=glorot_uniform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=16, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=16, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=16, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=150, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=50, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=150, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=50, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=150, optimizer=Adam, init=normal\n",
      "Best Validation Accuracy: 0.4536082446575165\n",
      "Best Hyperparameters: batch_size=32, epochs=50, optimizer=Adam, init=normal\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50, 100, 150],\n",
    "    'optimizer': ['SGD', 'Adam'],\n",
    "    'init': ['glorot_uniform', 'normal']\n",
    "}\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "combinations = list(product(param_grid['batch_size'], param_grid['epochs'], param_grid['optimizer'], param_grid['init']))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for batch_size, epochs, optimizer, init in combinations:\n",
    "    print(f\"Training with batch_size={batch_size}, epochs={epochs}, optimizer={optimizer}, init={init}\")\n",
    "    model, val_accuracy = create_and_train_model(X_train_sample, y_train_sample, X_test_sample, y_test_sample, optimizer=optimizer, init=init, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_params = (batch_size, epochs, optimizer, init)\n",
    "        best_model = model\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Hyperparameters: batch_size={best_params[0]}, epochs={best_params[1]}, optimizer={best_params[2]}, init={best_params[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3494 - loss: 1.1156\n",
      "Epoch 2/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3799 - loss: 1.0894\n",
      "Epoch 3/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4322 - loss: 1.0575\n",
      "Epoch 4/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4685 - loss: 1.0246\n",
      "Epoch 5/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4846 - loss: 1.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 0.9841\n",
      "Epoch 7/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: 0.9776\n",
      "Epoch 8/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 0.9612\n",
      "Epoch 9/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5410 - loss: 0.9413\n",
      "Epoch 10/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5481 - loss: 0.9182\n",
      "Epoch 11/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 0.9249\n",
      "Epoch 12/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5568 - loss: 0.9076\n",
      "Epoch 13/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 0.8735\n",
      "Epoch 14/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5777 - loss: 0.8693\n",
      "Epoch 15/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 0.8669\n",
      "Epoch 16/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8371\n",
      "Epoch 17/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.8271\n",
      "Epoch 18/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.8198\n",
      "Epoch 19/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.7996\n",
      "Epoch 20/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.7931\n",
      "Epoch 21/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6447 - loss: 0.7691\n",
      "Epoch 22/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 0.7499\n",
      "Epoch 23/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.7393\n",
      "Epoch 24/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6644 - loss: 0.7254\n",
      "Epoch 25/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6663 - loss: 0.7339\n",
      "Epoch 26/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.6937\n",
      "Epoch 27/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.6858\n",
      "Epoch 28/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.6878\n",
      "Epoch 29/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7007 - loss: 0.6680\n",
      "Epoch 30/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.6633\n",
      "Epoch 31/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.6557\n",
      "Epoch 32/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.6299\n",
      "Epoch 33/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.6206\n",
      "Epoch 34/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.6153\n",
      "Epoch 35/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.6000\n",
      "Epoch 36/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6028\n",
      "Epoch 37/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.5837\n",
      "Epoch 38/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.5772\n",
      "Epoch 39/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5679\n",
      "Epoch 40/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5614\n",
      "Epoch 41/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7574 - loss: 0.5465\n",
      "Epoch 42/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7649 - loss: 0.5374\n",
      "Epoch 43/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7626 - loss: 0.5383\n",
      "Epoch 44/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.5351\n",
      "Epoch 45/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.5230\n",
      "Epoch 46/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.5122\n",
      "Epoch 47/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.5171\n",
      "Epoch 48/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.5014\n",
      "Epoch 49/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.5102\n",
      "Epoch 50/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19f24ed9dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_batch_size, best_epochs, best_optimizer, best_init = best_params\n",
    "\n",
    "final_model = tf.keras.Sequential()\n",
    "final_model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer=best_init, input_shape=(X.shape[1],)))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "final_model.compile(optimizer=best_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "final_model.fit(X, y, epochs=best_epochs, batch_size=best_batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.3350 \n",
      "Test accuracy: 0.8762376308441162\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy: 0.8762376237623762\n",
      "Confusion Matrix:\n",
      "[[829   8  14]\n",
      " [136 615  22]\n",
      " [ 95  25 680]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87       851\n",
      "           1       0.95      0.80      0.87       773\n",
      "           2       0.95      0.85      0.90       800\n",
      "\n",
      "    accuracy                           0.88      2424\n",
      "   macro avg       0.89      0.87      0.88      2424\n",
      "weighted avg       0.89      0.88      0.88      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on a hold-out test set or cross-validation\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test_full, y_test_full)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test_full)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_full, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9696, 1536)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#  save final model\n",
    "final_model.save('final_model.h5')\n",
    "# load final model\n",
    "# loaded_model = tf.keras.models.load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولم...</td>\n",
       "      <td>کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی...</td>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>هذا هو ما تم نصحنا به.</td>\n",
       "      <td>عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت ال...</td>\n",
       "      <td>ar</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>et cela est en grande partie dû au fait que le...</td>\n",
       "      <td>Les mères se droguent.</td>\n",
       "      <td>fr</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>与城市及其他公民及社区组织代表就IMA的艺术发展进行对话&amp;amp</td>\n",
       "      <td>IMA与其他组织合作，因为它们都依靠共享资金。</td>\n",
       "      <td>zh</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>Она все еще была там.</td>\n",
       "      <td>Мы думали, что она ушла, однако, она осталась.</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f90dd59b0</td>\n",
       "      <td>نیند نے وعدہ کیا کہ موٹل نے سوال میں تحقیق کی.</td>\n",
       "      <td>نیمیتھ کو موٹل کی تفتیش کے لئے معاوضہ دیا جارہ...</td>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>f357a04e86</td>\n",
       "      <td>The  rock  has a soft texture and can be bough...</td>\n",
       "      <td>The rock is harder than most types of rock.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1f0ea92118</td>\n",
       "      <td>她目前的存在，并考虑到他与沃佛斯顿争执的本质，那是尴尬的。</td>\n",
       "      <td>她在与Wolverstone的打斗结束后才在场的事实被看作是很尴尬的。</td>\n",
       "      <td>zh</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0407b48afb</td>\n",
       "      <td>isn't it i can remember i've only been here ei...</td>\n",
       "      <td>I could see downtown Dallas from where I lived...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>16c2f2ab89</td>\n",
       "      <td>In Hong Kong you can have a plate, or even a w...</td>\n",
       "      <td>It's impossible to have a plate hand-painted t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            premise  \\\n",
       "0     c6d58c3f69  بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولم...   \n",
       "1     cefcc82292                             هذا هو ما تم نصحنا به.   \n",
       "2     e98005252c  et cela est en grande partie dû au fait que le...   \n",
       "3     58518c10ba                   与城市及其他公民及社区组织代表就IMA的艺术发展进行对话&amp   \n",
       "4     c32b0d16df                              Она все еще была там.   \n",
       "...          ...                                                ...   \n",
       "5190  5f90dd59b0     نیند نے وعدہ کیا کہ موٹل نے سوال میں تحقیق کی.   \n",
       "5191  f357a04e86  The  rock  has a soft texture and can be bough...   \n",
       "5192  1f0ea92118                      她目前的存在，并考虑到他与沃佛斯顿争执的本质，那是尴尬的。   \n",
       "5193  0407b48afb  isn't it i can remember i've only been here ei...   \n",
       "5194  16c2f2ab89  In Hong Kong you can have a plate, or even a w...   \n",
       "\n",
       "                                             hypothesis lang_abv language  \n",
       "0     کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی...       ur     Urdu  \n",
       "1     عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت ال...       ar   Arabic  \n",
       "2                                Les mères se droguent.       fr   French  \n",
       "3                               IMA与其他组织合作，因为它们都依靠共享资金。       zh  Chinese  \n",
       "4        Мы думали, что она ушла, однако, она осталась.       ru  Russian  \n",
       "...                                                 ...      ...      ...  \n",
       "5190  نیمیتھ کو موٹل کی تفتیش کے لئے معاوضہ دیا جارہ...       ur     Urdu  \n",
       "5191        The rock is harder than most types of rock.       en  English  \n",
       "5192                她在与Wolverstone的打斗结束后才在场的事实被看作是很尴尬的。       zh  Chinese  \n",
       "5193  I could see downtown Dallas from where I lived...       en  English  \n",
       "5194  It's impossible to have a plate hand-painted t...       en  English  \n",
       "\n",
       "[5195 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/embeddings_test_x.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5195, 1536)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n"
     ]
    }
   ],
   "source": [
    "test = scaler.transform(test)\n",
    "y_pred = final_model.predict(test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes\n",
    "results_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'prediction': y_pred_classes\n",
    "})\n",
    "results_df.to_csv('results/nn_predicted_results.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
