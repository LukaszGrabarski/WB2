{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, XLMRobertaModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/embeddings_train_x.csv')\n",
    "y = pd.read_csv('data/train.csv')['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate plot of variance explained vs number of components\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "def plot_variance_explained_vs_components(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    # add a horizontal line at 95% and 90%\n",
    "    plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "    plt.axhline(y=0.90, color='g', linestyle='--')\n",
    "    # calculate the number of components that explain 95% and 90% of the variance\n",
    "    n_components_95 = np.where(np.cumsum(pca.explained_variance_ratio_) > 0.95)[0][0]\n",
    "    n_components_90 = np.where(np.cumsum(pca.explained_variance_ratio_) > 0.90)[0][0]\n",
    "    plt.axvline(x=n_components_95, color='r', linestyle='--')\n",
    "    plt.axvline(x=n_components_90, color='g', linestyle='--')\n",
    "    # mark at x axis the number of components that explain 95% and 90% of the variance\n",
    "    plt.text(n_components_95, 0.7, f'n_components = {n_components_95}')\n",
    "    plt.text(n_components_90, 0.5, f'n_components = {n_components_90}')\n",
    "    plt.show()\n",
    "\n",
    "plot_variance_explained_vs_components(X_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=35)\n",
    "X_train_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train_pca, y_train)\n",
    "# y_pred = rf.predict(pca.transform(X_val))\n",
    "# print(accuracy_score(y_val, y_pred))\n",
    "# print(confusion_matrix(y_val, y_pred))\n",
    "# print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3721122112211221\n",
      "[[180 110 146]\n",
      " [137 134 118]\n",
      " [151  99 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.41      0.40       436\n",
      "           1       0.39      0.34      0.37       389\n",
      "           2       0.34      0.35      0.35       387\n",
      "\n",
      "    accuracy                           0.37      1212\n",
      "   macro avg       0.37      0.37      0.37      1212\n",
      "weighted avg       0.37      0.37      0.37      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42, max_depth=10, min_samples_leaf=1, min_samples_split=5)\n",
    "rf.fit(X_train_pca, y_train)\n",
    "y_pred = rf.predict(pca.transform(X_val))\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3314 - loss: 1.2217 - val_accuracy: 0.3336 - val_loss: 1.0974\n",
      "Epoch 2/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3533 - loss: 1.0969 - val_accuracy: 0.3419 - val_loss: 1.0955\n",
      "Epoch 3/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3505 - loss: 1.0945 - val_accuracy: 0.3538 - val_loss: 1.0944\n",
      "Epoch 4/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3558 - loss: 1.0917 - val_accuracy: 0.3593 - val_loss: 1.0935\n",
      "Epoch 5/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3503 - loss: 1.0936 - val_accuracy: 0.3611 - val_loss: 1.0924\n",
      "Epoch 6/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3573 - loss: 1.0904 - val_accuracy: 0.3731 - val_loss: 1.0906\n",
      "Epoch 7/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3670 - loss: 1.0887 - val_accuracy: 0.3859 - val_loss: 1.0858\n",
      "Epoch 8/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.0884 - val_accuracy: 0.4115 - val_loss: 1.0846\n",
      "Epoch 9/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3765 - loss: 1.0850 - val_accuracy: 0.4070 - val_loss: 1.0765\n",
      "Epoch 10/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3954 - loss: 1.0772 - val_accuracy: 0.4326 - val_loss: 1.0708\n",
      "Epoch 11/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4035 - loss: 1.0724 - val_accuracy: 0.4152 - val_loss: 1.0728\n",
      "Epoch 12/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3995 - loss: 1.0672 - val_accuracy: 0.4445 - val_loss: 1.0655\n",
      "Epoch 13/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4148 - loss: 1.0650 - val_accuracy: 0.4262 - val_loss: 1.0634\n",
      "Epoch 14/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4205 - loss: 1.0564 - val_accuracy: 0.4436 - val_loss: 1.0644\n",
      "Epoch 15/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.0492 - val_accuracy: 0.4427 - val_loss: 1.0609\n",
      "Epoch 16/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.0483 - val_accuracy: 0.4482 - val_loss: 1.0526\n",
      "Epoch 17/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4233 - loss: 1.0458 - val_accuracy: 0.4363 - val_loss: 1.0503\n",
      "Epoch 18/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4126 - loss: 1.0478 - val_accuracy: 0.4528 - val_loss: 1.0515\n",
      "Epoch 19/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4300 - loss: 1.0398 - val_accuracy: 0.4317 - val_loss: 1.0528\n",
      "Epoch 20/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4255 - loss: 1.0454 - val_accuracy: 0.4693 - val_loss: 1.0305\n",
      "Epoch 21/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4377 - loss: 1.0434 - val_accuracy: 0.4372 - val_loss: 1.0497\n",
      "Epoch 22/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4481 - loss: 1.0225 - val_accuracy: 0.4427 - val_loss: 1.0373\n",
      "Epoch 23/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4487 - loss: 1.0300 - val_accuracy: 0.4500 - val_loss: 1.0377\n",
      "Epoch 24/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4488 - loss: 1.0305 - val_accuracy: 0.4363 - val_loss: 1.0444\n",
      "Epoch 25/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4528 - loss: 1.0275 - val_accuracy: 0.4500 - val_loss: 1.0311\n",
      "Epoch 26/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4566 - loss: 1.0193 - val_accuracy: 0.4418 - val_loss: 1.0449\n",
      "Epoch 27/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4415 - loss: 1.0369 - val_accuracy: 0.4354 - val_loss: 1.0438\n",
      "Epoch 28/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4610 - loss: 1.0238 - val_accuracy: 0.4409 - val_loss: 1.0400\n",
      "Epoch 29/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4449 - loss: 1.0158 - val_accuracy: 0.4253 - val_loss: 1.0500\n",
      "Epoch 30/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4462 - loss: 1.0290 - val_accuracy: 0.4455 - val_loss: 1.0333\n",
      "Epoch 31/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4622 - loss: 1.0111 - val_accuracy: 0.4546 - val_loss: 1.0442\n",
      "Epoch 32/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4586 - loss: 1.0105 - val_accuracy: 0.4702 - val_loss: 1.0266\n",
      "Epoch 33/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4631 - loss: 1.0110 - val_accuracy: 0.4491 - val_loss: 1.0329\n",
      "Epoch 34/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4630 - loss: 1.0176 - val_accuracy: 0.4482 - val_loss: 1.0286\n",
      "Epoch 35/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4556 - loss: 1.0183 - val_accuracy: 0.4812 - val_loss: 1.0265\n",
      "Epoch 36/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4755 - loss: 1.0055 - val_accuracy: 0.4730 - val_loss: 1.0250\n",
      "Epoch 37/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4658 - loss: 1.0089 - val_accuracy: 0.4409 - val_loss: 1.0393\n",
      "Epoch 38/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4697 - loss: 1.0039 - val_accuracy: 0.4583 - val_loss: 1.0275\n",
      "Epoch 39/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 1.0054 - val_accuracy: 0.4665 - val_loss: 1.0216\n",
      "Epoch 40/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4810 - loss: 0.9913 - val_accuracy: 0.4510 - val_loss: 1.0417\n",
      "Epoch 41/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4704 - loss: 1.0044 - val_accuracy: 0.4629 - val_loss: 1.0255\n",
      "Epoch 42/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4716 - loss: 1.0008 - val_accuracy: 0.4748 - val_loss: 1.0267\n",
      "Epoch 43/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4682 - loss: 1.0028 - val_accuracy: 0.4427 - val_loss: 1.0397\n",
      "Epoch 44/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4739 - loss: 1.0043 - val_accuracy: 0.4675 - val_loss: 1.0196\n",
      "Epoch 45/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4723 - loss: 1.0007 - val_accuracy: 0.4528 - val_loss: 1.0215\n",
      "Epoch 46/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4857 - loss: 0.9905 - val_accuracy: 0.4299 - val_loss: 1.0473\n",
      "Epoch 47/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4646 - loss: 1.0053 - val_accuracy: 0.4620 - val_loss: 1.0237\n",
      "Epoch 48/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4714 - loss: 1.0089 - val_accuracy: 0.4427 - val_loss: 1.0269\n",
      "Epoch 49/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4768 - loss: 1.0050 - val_accuracy: 0.4702 - val_loss: 1.0209\n",
      "Epoch 50/50\n",
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4790 - loss: 0.9939 - val_accuracy: 0.4601 - val_loss: 1.0211\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_val_encoded = to_categorical(y_val)\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add input layer and first hidden layer\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add second hidden layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(units=y_train_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4730 - loss: 1.0265\n",
      "Test accuracy: 0.4587458670139313\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Accuracy: 0.45874587458745875\n",
      "Confusion Matrix:\n",
      "[[315 103  18]\n",
      " [242 128  19]\n",
      " [201  73 113]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.72      0.53       436\n",
      "           1       0.42      0.33      0.37       389\n",
      "           2       0.75      0.29      0.42       387\n",
      "\n",
      "    accuracy                           0.46      1212\n",
      "   macro avg       0.53      0.45      0.44      1212\n",
      "weighted avg       0.53      0.46      0.44      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val_encoded)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_val_encoded, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(X_train, y_train, X_val, y_val, optimizer='adam', init='glorot_uniform', epochs=50, batch_size=32):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer=init, input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=init))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer=init))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=0)\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    return model, val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y).values\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create a representative sample of the data (e.g., 20% of the dataset)\n",
    "X_sample, _, y_sample, _ = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=16, epochs=50, optimizer=SGD, init=glorot_uniform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=16, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=16, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=16, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=16, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=16, epochs=150, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=50, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=32, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=32, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=32, epochs=150, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=50, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=50, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=50, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=50, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=100, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=100, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=100, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=100, optimizer=Adam, init=normal\n",
      "Training with batch_size=64, epochs=150, optimizer=SGD, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=150, optimizer=SGD, init=normal\n",
      "Training with batch_size=64, epochs=150, optimizer=Adam, init=glorot_uniform\n",
      "Training with batch_size=64, epochs=150, optimizer=Adam, init=normal\n",
      "Best Validation Accuracy: 0.4536082446575165\n",
      "Best Hyperparameters: batch_size=32, epochs=50, optimizer=Adam, init=normal\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50, 100, 150],\n",
    "    'optimizer': ['SGD', 'Adam'],\n",
    "    'init': ['glorot_uniform', 'normal']\n",
    "}\n",
    "\n",
    "# Create combinations of hyperparameters\n",
    "combinations = list(product(param_grid['batch_size'], param_grid['epochs'], param_grid['optimizer'], param_grid['init']))\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for batch_size, epochs, optimizer, init in combinations:\n",
    "    print(f\"Training with batch_size={batch_size}, epochs={epochs}, optimizer={optimizer}, init={init}\")\n",
    "    model, val_accuracy = create_and_train_model(X_train_sample, y_train_sample, X_test_sample, y_test_sample, optimizer=optimizer, init=init, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_params = (batch_size, epochs, optimizer, init)\n",
    "        best_model = model\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Hyperparameters: batch_size={best_params[0]}, epochs={best_params[1]}, optimizer={best_params[2]}, init={best_params[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3494 - loss: 1.1156\n",
      "Epoch 2/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3799 - loss: 1.0894\n",
      "Epoch 3/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4322 - loss: 1.0575\n",
      "Epoch 4/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4685 - loss: 1.0246\n",
      "Epoch 5/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4846 - loss: 1.0050\n",
      "Epoch 6/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 0.9841\n",
      "Epoch 7/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: 0.9776\n",
      "Epoch 8/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 0.9612\n",
      "Epoch 9/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5410 - loss: 0.9413\n",
      "Epoch 10/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5481 - loss: 0.9182\n",
      "Epoch 11/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 0.9249\n",
      "Epoch 12/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5568 - loss: 0.9076\n",
      "Epoch 13/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 0.8735\n",
      "Epoch 14/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5777 - loss: 0.8693\n",
      "Epoch 15/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5848 - loss: 0.8669\n",
      "Epoch 16/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.8371\n",
      "Epoch 17/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6113 - loss: 0.8271\n",
      "Epoch 18/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 0.8198\n",
      "Epoch 19/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6295 - loss: 0.7996\n",
      "Epoch 20/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.7931\n",
      "Epoch 21/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6447 - loss: 0.7691\n",
      "Epoch 22/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 0.7499\n",
      "Epoch 23/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.7393\n",
      "Epoch 24/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6644 - loss: 0.7254\n",
      "Epoch 25/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6663 - loss: 0.7339\n",
      "Epoch 26/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.6937\n",
      "Epoch 27/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.6858\n",
      "Epoch 28/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.6878\n",
      "Epoch 29/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7007 - loss: 0.6680\n",
      "Epoch 30/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6916 - loss: 0.6633\n",
      "Epoch 31/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.6557\n",
      "Epoch 32/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.6299\n",
      "Epoch 33/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.6206\n",
      "Epoch 34/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.6153\n",
      "Epoch 35/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.6000\n",
      "Epoch 36/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6028\n",
      "Epoch 37/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.5837\n",
      "Epoch 38/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.5772\n",
      "Epoch 39/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5679\n",
      "Epoch 40/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5614\n",
      "Epoch 41/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7574 - loss: 0.5465\n",
      "Epoch 42/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7649 - loss: 0.5374\n",
      "Epoch 43/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7626 - loss: 0.5383\n",
      "Epoch 44/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.5351\n",
      "Epoch 45/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.5230\n",
      "Epoch 46/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7731 - loss: 0.5122\n",
      "Epoch 47/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.5171\n",
      "Epoch 48/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.5014\n",
      "Epoch 49/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.5102\n",
      "Epoch 50/50\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - loss: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19f24ed9dc0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_batch_size, best_epochs, best_optimizer, best_init = best_params\n",
    "\n",
    "final_model = tf.keras.Sequential()\n",
    "final_model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer=best_init, input_shape=(X.shape[1],)))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "final_model.compile(optimizer=best_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "final_model.fit(X, y, epochs=best_epochs, batch_size=best_batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = to_categorical(y_train)\n",
    "y_val_encoded = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piotr\\Desktop\\WB2\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3431 - loss: 1.1053\n",
      "Epoch 2/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3516 - loss: 1.0967\n",
      "Epoch 3/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3716 - loss: 1.0908\n",
      "Epoch 4/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3790 - loss: 1.0858\n",
      "Epoch 5/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3962 - loss: 1.0807\n",
      "Epoch 6/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4293 - loss: 1.0600\n",
      "Epoch 7/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4364 - loss: 1.0426\n",
      "Epoch 8/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4593 - loss: 1.0328\n",
      "Epoch 9/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4701 - loss: 1.0210\n",
      "Epoch 10/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4725 - loss: 1.0160\n",
      "Epoch 11/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4764 - loss: 1.0027\n",
      "Epoch 12/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4848 - loss: 1.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4856 - loss: 0.9996\n",
      "Epoch 14/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4969 - loss: 0.9869\n",
      "Epoch 15/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5054 - loss: 0.9753\n",
      "Epoch 16/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5046 - loss: 0.9838\n",
      "Epoch 17/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: 0.9721\n",
      "Epoch 18/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 0.9679\n",
      "Epoch 19/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5113 - loss: 0.9634\n",
      "Epoch 20/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5178 - loss: 0.9539\n",
      "Epoch 21/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5263 - loss: 0.9496\n",
      "Epoch 22/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5250 - loss: 0.9439\n",
      "Epoch 23/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5268 - loss: 0.9571\n",
      "Epoch 24/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.9455\n",
      "Epoch 25/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5312 - loss: 0.9402\n",
      "Epoch 26/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5444 - loss: 0.9233\n",
      "Epoch 27/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5393 - loss: 0.9374\n",
      "Epoch 28/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5386 - loss: 0.9363\n",
      "Epoch 29/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5432 - loss: 0.9280\n",
      "Epoch 30/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 0.9378\n",
      "Epoch 31/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5447 - loss: 0.9197\n",
      "Epoch 32/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 0.9125\n",
      "Epoch 33/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 0.9045\n",
      "Epoch 34/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 0.9154\n",
      "Epoch 35/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5435 - loss: 0.9216\n",
      "Epoch 36/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 0.9106\n",
      "Epoch 37/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5525 - loss: 0.9082\n",
      "Epoch 38/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5515 - loss: 0.8985\n",
      "Epoch 39/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 0.8962\n",
      "Epoch 40/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5680 - loss: 0.8827\n",
      "Epoch 41/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5656 - loss: 0.8863\n",
      "Epoch 42/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5762 - loss: 0.8754\n",
      "Epoch 43/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5785 - loss: 0.8742\n",
      "Epoch 44/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5694 - loss: 0.8778\n",
      "Epoch 45/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5657 - loss: 0.8693\n",
      "Epoch 46/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5632 - loss: 0.8775\n",
      "Epoch 47/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5778 - loss: 0.8637\n",
      "Epoch 48/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5742 - loss: 0.8631\n",
      "Epoch 49/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 0.8567\n",
      "Epoch 50/50\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 0.8591\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4800 - loss: 1.0653\n",
      "Test accuracy: 0.4744224548339844\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.4744224422442244\n",
      "Confusion Matrix:\n",
      "[[242 156  38]\n",
      " [157 167  65]\n",
      " [128  93 166]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.56      0.50       436\n",
      "           1       0.40      0.43      0.41       389\n",
      "           2       0.62      0.43      0.51       387\n",
      "\n",
      "    accuracy                           0.47      1212\n",
      "   macro avg       0.49      0.47      0.47      1212\n",
      "weighted avg       0.49      0.47      0.48      1212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on a hold-out test set or cross-validation\n",
    "# X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "best_batch_size, best_epochs, best_optimizer, best_init = 32, 50, 'Adam', 'normal'\n",
    "\n",
    "final_model = tf.keras.Sequential()\n",
    "final_model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer=best_init, input_shape=(X.shape[1],)))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(32, activation='relu', kernel_initializer=best_init))\n",
    "final_model.add(tf.keras.layers.Dropout(0.3))\n",
    "final_model.add(tf.keras.layers.Dense(y_train_encoded.shape[1], activation='softmax'))\n",
    "final_model.compile(optimizer=best_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "final_model.fit(X_train, y_train_encoded, epochs=best_epochs, batch_size=best_batch_size, verbose=1)\n",
    "\n",
    "test_loss, test_accuracy = final_model.evaluate(X_val, y_val_encoded)\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_val_encoded, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#  save final model\n",
    "final_model.save('final_model.h5')\n",
    "# load final model\n",
    "# loaded_model = tf.keras.models.load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولم...</td>\n",
       "      <td>کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی...</td>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>هذا هو ما تم نصحنا به.</td>\n",
       "      <td>عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت ال...</td>\n",
       "      <td>ar</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>et cela est en grande partie dû au fait que le...</td>\n",
       "      <td>Les mères se droguent.</td>\n",
       "      <td>fr</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>与城市及其他公民及社区组织代表就IMA的艺术发展进行对话&amp;amp</td>\n",
       "      <td>IMA与其他组织合作，因为它们都依靠共享资金。</td>\n",
       "      <td>zh</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>Она все еще была там.</td>\n",
       "      <td>Мы думали, что она ушла, однако, она осталась.</td>\n",
       "      <td>ru</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f90dd59b0</td>\n",
       "      <td>نیند نے وعدہ کیا کہ موٹل نے سوال میں تحقیق کی.</td>\n",
       "      <td>نیمیتھ کو موٹل کی تفتیش کے لئے معاوضہ دیا جارہ...</td>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>f357a04e86</td>\n",
       "      <td>The  rock  has a soft texture and can be bough...</td>\n",
       "      <td>The rock is harder than most types of rock.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1f0ea92118</td>\n",
       "      <td>她目前的存在，并考虑到他与沃佛斯顿争执的本质，那是尴尬的。</td>\n",
       "      <td>她在与Wolverstone的打斗结束后才在场的事实被看作是很尴尬的。</td>\n",
       "      <td>zh</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0407b48afb</td>\n",
       "      <td>isn't it i can remember i've only been here ei...</td>\n",
       "      <td>I could see downtown Dallas from where I lived...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>16c2f2ab89</td>\n",
       "      <td>In Hong Kong you can have a plate, or even a w...</td>\n",
       "      <td>It's impossible to have a plate hand-painted t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            premise  \\\n",
       "0     c6d58c3f69  بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولم...   \n",
       "1     cefcc82292                             هذا هو ما تم نصحنا به.   \n",
       "2     e98005252c  et cela est en grande partie dû au fait que le...   \n",
       "3     58518c10ba                   与城市及其他公民及社区组织代表就IMA的艺术发展进行对话&amp   \n",
       "4     c32b0d16df                              Она все еще была там.   \n",
       "...          ...                                                ...   \n",
       "5190  5f90dd59b0     نیند نے وعدہ کیا کہ موٹل نے سوال میں تحقیق کی.   \n",
       "5191  f357a04e86  The  rock  has a soft texture and can be bough...   \n",
       "5192  1f0ea92118                      她目前的存在，并考虑到他与沃佛斯顿争执的本质，那是尴尬的。   \n",
       "5193  0407b48afb  isn't it i can remember i've only been here ei...   \n",
       "5194  16c2f2ab89  In Hong Kong you can have a plate, or even a w...   \n",
       "\n",
       "                                             hypothesis lang_abv language  \n",
       "0     کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی...       ur     Urdu  \n",
       "1     عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت ال...       ar   Arabic  \n",
       "2                                Les mères se droguent.       fr   French  \n",
       "3                               IMA与其他组织合作，因为它们都依靠共享资金。       zh  Chinese  \n",
       "4        Мы думали, что она ушла, однако, она осталась.       ru  Russian  \n",
       "...                                                 ...      ...      ...  \n",
       "5190  نیمیتھ کو موٹل کی تفتیش کے لئے معاوضہ دیا جارہ...       ur     Urdu  \n",
       "5191        The rock is harder than most types of rock.       en  English  \n",
       "5192                她在与Wolverstone的打斗结束后才在场的事实被看作是很尴尬的。       zh  Chinese  \n",
       "5193  I could see downtown Dallas from where I lived...       en  English  \n",
       "5194  It's impossible to have a plate hand-painted t...       en  English  \n",
       "\n",
       "[5195 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/embeddings_test_x.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5195, 1536)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n"
     ]
    }
   ],
   "source": [
    "test = scaler.transform(test)\n",
    "y_pred = final_model.predict(test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes\n",
    "results_df = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'prediction': y_pred_classes\n",
    "})\n",
    "results_df.to_csv('results/nn_predicted_results.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
